{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "616a85e8",
   "metadata": {},
   "source": [
    "<p align = \"center\" draggable=‚Äùfalse‚Äù ><img src=\"https://user-images.githubusercontent.com/37101144/161836199-fdb0219d-0361-4988-bf26-48b0fad160a3.png\" \n",
    "     width=\"200px\"\n",
    "     height=\"auto\"/>\n",
    "</p>\n",
    "\n",
    "# Reddit and HuggingFace Starter Kit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddd542f",
   "metadata": {},
   "source": [
    "## Part I: [Reddit API](https://www.reddit.com/dev/api/)\n",
    "The first part of this excercise is to figure out how to instantiate a Reddit API object using the Python Reddit API Wrapper [PRAW](https://praw.readthedocs.io/en/stable/).  PRAW is a Python library that provides a simple interfaceto interact with the Reddit API.\n",
    "\n",
    "### Your Task\n",
    "You will first need to instantiate a [Reddit instance](https://praw.readthedocs.io/en/stable/code_overview/reddit_instance.html).\n",
    "Hint: you only need to use `client_id`, `client_secret`, and `user_agent`\n",
    "\n",
    "#### Make sure everyone in the group does this part! \n",
    "\n",
    "Follow the guide below on how to get your `client_id` and `client_secret`.\n",
    "\n",
    "#### Follow these steps:\n",
    "1. Pull the `FourthBrain/ML03` repo locally so you can start development.\n",
    "2. Open `reddit_and_huggingface.ipynb` and install the necessary packages for this lesson by running:\n",
    "\n",
    "    ```\n",
    "    cd code_student/Week_2\n",
    "    conda activate {your_virtual_environment_name}\n",
    "    pip install transformers praw torch torchvision torchaudio\n",
    "    ```\n",
    "    \n",
    "3. Obtain your `client_id` and `client_secret`\n",
    "\n",
    "* Make a Reddit account\n",
    "* Follow the steps in this screenshot which are the first steps from this [guide](https://towardsdatascience.com/how-to-use-the-reddit-api-in-python-5e05ddfd1e5c).\n",
    "\n",
    "![instructions to set up reddit api](../../images/reddit_get_access.JPG)\n",
    "\n",
    "* Create a `secrets.py` file and include the following:\n",
    "\n",
    "    ```\n",
    "    REDDIT_API_CLIENT_ID = \"\"\n",
    "    REDDIT_API_CLIENT_SECRET = \"\"\n",
    "    REDDIT_API_USER_AGENT = {can_be_any_string...for ex: \"teslabot\"}\n",
    "    ```\n",
    "    Get it?  [Teslabot :)](https://www.tesla.com/AIhttps://www.tesla.com/AI)\n",
    "    \n",
    "\n",
    "* Put `secrets.py` in `Week_2` so you can easily import it\n",
    "\n",
    "4. Complete the code in the `# YOUR CODE HERE` space below that creates a reddit instance object that allows us to interact with the Reddit API.  Note that the `subreddit` object for the 'r/TSLA' subreddit has already been created for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5e6fd4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda3/envs/reddit_bot/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import praw\n",
    "from transformers import pipeline\n",
    "import secrets\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    # YOUR CODE HERE\n",
    "    client_id=secrets.REDDIT_API_CLIENT_ID,\n",
    "    client_secret=secrets.REDDIT_API_CLIENT_SECRET,\n",
    "    user_agent=secrets.REDDIT_API_USER_AGENT,\n",
    ")\n",
    "\n",
    "subreddit = reddit.subreddit('TSLA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4d2630",
   "metadata": {},
   "source": [
    "## Part II:  [r/TSLA Subreddit](https://www.reddit.com/r/TSLA/)\n",
    "The second part of this exercise is to figure out how to the following code is parsing comments through use of the r/TSLA `subreddit` instance object.\n",
    "\n",
    "### Your Task\n",
    "1. Work with your group to comment each line of the following code so that you describe what each piece is doing.\n",
    "2. Create one comment at the top of the code that describes what the larger for loop is iterating over.  \n",
    "3. (Optional) How many comments will I get from this?\n",
    "\n",
    "A few resources that might help!\n",
    "* How do I find the top 10 posts of all time from your favorite subreddit(s)? (hint: look at [\"Obtain Submission Instances from a Subreddit\"](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html))\n",
    "* How do I parse comments from the post? (hint: look at [\"Obtain Submission Instances from a Subreddit\"](https://praw.readthedocs.io/en/stable/getting_started/quick_start.html))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "822c8a83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comments:  167\n"
     ]
    }
   ],
   "source": [
    "#Load packages\n",
    "from praw.models import MoreComments\n",
    "#Initialize an empty list to store the comments\n",
    "top_comments = []\n",
    "\n",
    "#Looping on the top 10 submissions of the subreddit instance\n",
    "for submission in subreddit.top(limit=10):\n",
    "    #Looping on each comment from the submission\n",
    "    for top_level_comment in submission.comments:\n",
    "        #Ignore more comments objects. The ones causing the AttributeError: 'MoreComments' object has no attribute 'body'\n",
    "        if isinstance(top_level_comment, MoreComments):\n",
    "                    continue\n",
    "        #Append comments to the list     \n",
    "        top_comments.append(top_level_comment.body)\n",
    "\n",
    "print('Number of comments: ', len(top_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cbe98b",
   "metadata": {},
   "source": [
    "## Part III:  [HuggingFace](https://huggingface.co/docs/transformers/quicktour)\n",
    "The third part of this exercise is to analyze the sentiment of each comment scraped from `r/TSLA` to using a pre-trained HuggingFace model to make the inference. \n",
    "\n",
    "### Your Task\n",
    "1. Implement the [Sentiment Analysis](https://huggingface.co/docs/transformers/quicktour) Model in the `# YOUR CODE HERE` section. \n",
    "2. (Optional) What is the net sentiment of the entire list of comments?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "147017d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english)\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# YOUR CODE HERE\n",
    "sentiment_model = pipeline(\"sentiment-analysis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2afb4406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment test: \n",
      "Right now, it's actually a great opportunity to buy TSLA at such a huge discount. When it's back over 800, we'll already have locked in a 35% gain! üòéüëç === [{'label': 'POSITIVE', 'score': 0.979337215423584}]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "def get_random_comment(conversations):\n",
    "    comment = random.choice(conversations)\n",
    "    return comment\n",
    "\n",
    "# Run sentiment analysis\n",
    "sentiment_query_sentence = get_random_comment(top_comments) # grabs a random comment from the comment and replies list\n",
    "sentiment = sentiment_model(sentiment_query_sentence) # \n",
    "print(f\"Sentiment test: {sentiment_query_sentence} === {sentiment}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "954d745e",
   "metadata": {},
   "source": [
    "### Net Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f9a8e72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Score....:  -0.2689068713587915\n"
     ]
    }
   ],
   "source": [
    "#Get sentinment for all comments\n",
    "sentiment_full = sentiment_model(top_comments)\n",
    "\n",
    "#Initiate an empty list to store all scores \n",
    "scores = []\n",
    "for comment in sentiment_full:\n",
    "    #If comment is negative the score will be multiplied by -1\n",
    "    if comment['label'] == 'NEGATIVE':\n",
    "        comment['score_2'] = -1 * comment['score']\n",
    "        scores.append(comment['score_2'])\n",
    "    #Otherwise will be multiplied by 1\n",
    "    else:\n",
    "        comment['score_2'] = 1 * comment['score']\n",
    "        scores.append(comment['score_2'])\n",
    "\n",
    "#Calculate average\n",
    "print('Net Score....: ',sum(scores)/len(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca67fc4",
   "metadata": {},
   "source": [
    "The net score seems to be negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a6c410",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
